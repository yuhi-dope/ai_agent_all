"""
ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã€‚
GitHub OAuth / Supabase PAT / Vercel Token ã‚’ä½¿ã£ã¦
ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¼æ¥­ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚’è‡ªå‹•æ§‹ç¯‰ã™ã‚‹ã€‚
"""

import base64
import logging
import secrets

import httpx

from server import company as company_module
from server import oauth_store

logger = logging.getLogger(__name__)

# ---------- ãƒœã‚¤ãƒ©ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ----------
# onboarding.sh ã¨åŒä¸€ã® Next.js ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

_PACKAGE_JSON = """{
  "name": "client-dashboard",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "next": "^14.2.0",
    "react": "^18.3.0",
    "react-dom": "^18.3.0",
    "@supabase/supabase-js": "^2.45.0"
  },
  "devDependencies": {
    "typescript": "^5.5.0",
    "@types/node": "^20.14.0",
    "@types/react": "^18.3.0",
    "@types/react-dom": "^18.3.0",
    "tailwindcss": "^3.4.0",
    "postcss": "^8.4.0",
    "autoprefixer": "^10.4.0",
    "eslint": "^8.57.0",
    "eslint-config-next": "^14.2.0"
  }
}"""

_TSCONFIG_JSON = """{
  "compilerOptions": {
    "target": "es5",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [{ "name": "next" }],
    "paths": { "@/*": ["./src/*"] }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}"""

_NEXT_CONFIG_JS = """/** @type {import('next').NextConfig} */
const nextConfig = {}
module.exports = nextConfig"""

_TAILWIND_CONFIG_TS = """import type { Config } from "tailwindcss";

const config: Config = {
  content: [
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: { extend: {} },
  plugins: [],
};
export default config;"""

_POSTCSS_CONFIG_JS = """module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}"""

_GITIGNORE = """node_modules/
.next/
out/
.env.local
.vercel
*.tsbuildinfo
next-env.d.ts"""

_SUPABASE_TS = """import { createClient } from "@supabase/supabase-js";

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;

export const supabase = createClient(supabaseUrl, supabaseAnonKey);"""

_GENRES_TS = """export type Genre = {
  id: string;
  title: string;
  icon: string;
  description: string;
};

export const genres: Genre[] = [
  { id: "sfa",        title: "SFA/\\u55b6\\u696dã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",       icon: "\\ud83d\\udcca", description: "å•†è«‡ç®¡ç†ãƒ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ»è¦‹ç©æ›¸ã‚’ä¸€å…ƒç®¡ç†" },
  { id: "crm",        title: "CRMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",            icon: "\\ud83d\\udc65", description: "é¡§å®¢æƒ…å ±ãƒ»é–¢ä¿‚å±¥æ­´ãƒ»ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚’ç®¡ç†" },
  { id: "accounting", title: "ä¼šè¨ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",            icon: "\\ud83d\\udcb4", description: "è«‹æ±‚ãƒ»ä»•è¨³ãƒ»è²¡å‹™åˆ†æã‚’è‡ªå‹•åŒ–" },
  { id: "legal",      title: "æ³•å‹™ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",            icon: "\\u2696\\ufe0f", description: "å¥‘ç´„æ›¸ãƒ»ç¨Ÿè­°ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’ç®¡ç†" },
  { id: "admin",      title: "äº‹å‹™ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",            icon: "\\ud83d\\udcdd", description: "æ—¥å ±ãƒ»çµŒè²»ãƒ»å‹¤æ€ ãƒ»ç”³è«‹æ¥­å‹™ã‚’åŠ¹ç‡åŒ–" },
  { id: "it",         title: "æƒ…ã‚·ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",          icon: "\\ud83d\\udda5\\ufe0f", description: "ITè³‡ç”£ãƒ»ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã‚’ä¸€å…ƒç®¡ç†" },
  { id: "marketing",  title: "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",  icon: "\\ud83d\\udce3", description: "é›†å®¢ãƒ»åºƒå‘Šãƒ»æ–½ç­–åŠ¹æœã‚’å¯è¦–åŒ–" },
  { id: "design",     title: "ãƒ‡ã‚¶ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",        icon: "\\ud83c\\udfa8", description: "UI/UXãƒ»åˆ¶ä½œç‰©ãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’ç®¡ç†" },
  { id: "ma",         title: "M&Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",             icon: "\\ud83c\\udfe2", description: "è²·åå€™è£œãƒ»DDãƒ»ä¼æ¥­ä¾¡å€¤åˆ†æã‚’æ”¯æ´" },
  { id: "no2",        title: "No.2/çµŒå–¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",       icon: "\\ud83e\\udde0", description: "KPIãƒ»çµŒå–¶åˆ†æãƒ»æˆ¦ç•¥æè¨€ã‚’æä¾›" },
];"""

_GLOBALS_CSS = """@tailwind base;
@tailwind components;
@tailwind utilities;"""

_SIDEBAR_TSX = """"use client";

import Link from "next/link";
import { usePathname } from "next/navigation";
import { genres } from "@/lib/genres";

export default function Sidebar() {
  const pathname = usePathname();

  return (
    <aside className="w-60 min-h-screen bg-slate-900 text-white flex flex-col">
      <div className="p-4 border-b border-slate-700">
        <h1 className="text-lg font-bold">
          {process.env.NEXT_PUBLIC_COMPANY_NAME || "Dashboard"}
        </h1>
      </div>
      <nav className="flex-1 py-2">
        <Link
          href="/"
          className={`block px-4 py-2 text-sm hover:bg-slate-800 ${
            pathname === "/" ? "bg-slate-800 font-bold" : ""
          }`}
        >
          ğŸ  ãƒ›ãƒ¼ãƒ 
        </Link>
        {genres.map((g) => (
          <Link
            key={g.id}
            href={`/${g.id}`}
            className={`block px-4 py-2 text-sm hover:bg-slate-800 ${
              pathname === `/${g.id}` ? "bg-slate-800 font-bold" : ""
            }`}
          >
            {g.icon} {g.title}
          </Link>
        ))}
      </nav>
    </aside>
  );
}"""

_LAYOUT_TSX = """import type { Metadata } from "next";
import "./globals.css";
import Sidebar from "@/components/layout/Sidebar";

export const metadata: Metadata = {
  title: "AIç¤¾å“¡ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
  description: "AIç¤¾å“¡ãŒæ§‹ç¯‰ã—ãŸæ¥­å‹™ã‚·ã‚¹ãƒ†ãƒ ",
};

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="ja">
      <body className="flex">
        <Sidebar />
        <main className="flex-1 min-h-screen bg-gray-50 p-6">
          {children}
        </main>
      </body>
    </html>
  );
}"""

_GENRECARD_TSX = """import Link from "next/link";
import type { Genre } from "@/lib/genres";

export default function GenreCard({ genre }: { genre: Genre }) {
  return (
    <Link
      href={`/${genre.id}`}
      className="block p-6 bg-white rounded-lg border border-gray-200 hover:shadow-md transition-shadow"
    >
      <div className="text-3xl mb-3">{genre.icon}</div>
      <h3 className="font-bold text-gray-900 mb-1">{genre.title}ã‚·ã‚¹ãƒ†ãƒ </h3>
      <p className="text-sm text-gray-500">{genre.description}</p>
    </Link>
  );
}"""

_HOME_TSX = """import GenreCard from "@/components/home/GenreCard";
import { genres } from "@/lib/genres";

export default function Home() {
  return (
    <div>
      <h1 className="text-2xl font-bold text-gray-900 mb-6">
        ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
      </h1>
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
        {genres.map((genre) => (
          <GenreCard key={genre.id} genre={genre} />
        ))}
      </div>
    </div>
  );
}"""

_GENRE_PAGE_TSX = """import { genres } from "@/lib/genres";
import { notFound } from "next/navigation";
import Link from "next/link";

export default function GenrePage({ params }: { params: { genre: string } }) {
  const genre = genres.find((g) => g.id === params.genre);
  if (!genre) return notFound();

  return (
    <div>
      <nav className="text-sm text-gray-500 mb-4">
        <Link href="/" className="hover:underline">ãƒ›ãƒ¼ãƒ </Link>
        <span className="mx-2">/</span>
        <span>{genre.title}</span>
      </nav>
      <h1 className="text-2xl font-bold text-gray-900 mb-2">
        {genre.icon} {genre.title}ã‚·ã‚¹ãƒ†ãƒ 
      </h1>
      <p className="text-gray-500 mb-8">{genre.description}</p>
      <div className="bg-white rounded-lg border border-gray-200 p-8 text-center text-gray-400">
        AIç¤¾å“¡ãŒã“ã®ã‚¸ãƒ£ãƒ³ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã¨ã€ã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
      </div>
    </div>
  );
}"""

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”¨ Supabase åˆæœŸãƒ†ãƒ¼ãƒ–ãƒ« SQL
_CLIENT_SUPABASE_SQL = """
CREATE TABLE IF NOT EXISTS agent_outputs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  company_id TEXT NOT NULL,
  genre TEXT NOT NULL,
  output_type TEXT,
  title TEXT,
  content JSONB,
  created_at TIMESTAMPTZ DEFAULT now()
);

ALTER TABLE agent_outputs ENABLE ROW LEVEL SECURITY;

DO $$
BEGIN
  IF NOT EXISTS (
    SELECT 1 FROM pg_policies WHERE policyname = 'agent_outputs_select'
  ) THEN
    CREATE POLICY "agent_outputs_select" ON agent_outputs
      FOR SELECT USING (company_id = current_setting('app.company_id', true));
  END IF;
  IF NOT EXISTS (
    SELECT 1 FROM pg_policies WHERE policyname = 'agent_outputs_insert'
  ) THEN
    CREATE POLICY "agent_outputs_insert" ON agent_outputs
      FOR INSERT WITH CHECK (company_id = current_setting('app.company_id', true));
  END IF;
END
$$;
"""


async def _run_sql_on_project(
    client: httpx.AsyncClient,
    project_ref: str,
    sql: str,
    mgmt_token: str = "",
    service_role_key: str = "",
) -> bool:
    """
    Supabase ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ SQL ã‚’å®Ÿè¡Œã™ã‚‹ã€‚3 ã¤ã®æ–¹æ³•ã‚’é †ã«è©¦ã™:
    1. pg-meta API (service_role ã‚­ãƒ¼ä½¿ç”¨)
    2. Management API /database/migrations
    3. Management API /database/query (ãƒ¬ã‚¬ã‚·ãƒ¼)
    """
    # æ–¹æ³• 1: pg-meta APIï¼ˆæœ€ã‚‚ç¢ºå®Ÿï¼‰
    if service_role_key:
        try:
            resp = await client.post(
                f"https://{project_ref}.supabase.co/pg/query",
                headers={
                    "apikey": service_role_key,
                    "Authorization": f"Bearer {service_role_key}",
                    "Content-Type": "application/json",
                },
                json={"query": sql},
            )
            if resp.status_code in (200, 201):
                logger.info("SQL executed via pg-meta API")
                return True
            logger.info("pg-meta failed: %s %s", resp.status_code, resp.text[:200])
        except Exception as e:
            logger.info("pg-meta exception: %s", e)

    # æ–¹æ³• 2: Management API /database/migrations
    if mgmt_token:
        mgmt_headers = {
            "Authorization": f"Bearer {mgmt_token}",
            "Content-Type": "application/json",
        }
        try:
            resp = await client.post(
                f"{_SUPABASE_MGMT_API}/v1/projects/{project_ref}/database/migrations",
                headers=mgmt_headers,
                json={"query": sql},
            )
            if resp.status_code in (200, 201):
                logger.info("SQL executed via migrations API")
                return True
            logger.info("migrations API failed: %s %s", resp.status_code, resp.text[:200])
        except Exception as e:
            logger.info("migrations API exception: %s", e)

    # æ–¹æ³• 3: ãƒ¬ã‚¬ã‚·ãƒ¼ /database/query
    if mgmt_token:
        try:
            resp = await client.post(
                f"{_SUPABASE_MGMT_API}/v1/projects/{project_ref}/database/query",
                headers={
                    "Authorization": f"Bearer {mgmt_token}",
                    "Content-Type": "application/json",
                },
                json={"query": sql},
            )
            if resp.status_code == 200:
                logger.info("SQL executed via query API")
                return True
            logger.info("query API failed: %s %s", resp.status_code, resp.text[:200])
        except Exception as e:
            logger.info("query API exception: %s", e)

    return False


def _env_local_example(company_name: str, repo_name: str) -> str:
    return f"""# Supabaseï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰
NEXT_PUBLIC_SUPABASE_URL=https://xxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJxxx

# ã‚¢ãƒ—ãƒªè¨­å®š
NEXT_PUBLIC_COMPANY_NAME={company_name}
NEXT_PUBLIC_APP_URL=https://{repo_name}.vercel.app"""


def _boilerplate_files(company_name: str, repo_name: str) -> dict[str, str]:
    """ãƒªãƒã‚¸ãƒˆãƒªã« push ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¿”ã™ã€‚{path: content}"""
    return {
        "package.json": _PACKAGE_JSON,
        "tsconfig.json": _TSCONFIG_JSON,
        "next.config.js": _NEXT_CONFIG_JS,
        "tailwind.config.ts": _TAILWIND_CONFIG_TS,
        "postcss.config.js": _POSTCSS_CONFIG_JS,
        ".gitignore": _GITIGNORE,
        ".env.local.example": _env_local_example(company_name, repo_name),
        "src/lib/supabase.ts": _SUPABASE_TS,
        "src/lib/genres.ts": _GENRES_TS,
        "src/app/globals.css": _GLOBALS_CSS,
        "src/components/layout/Sidebar.tsx": _SIDEBAR_TSX,
        "src/app/layout.tsx": _LAYOUT_TSX,
        "src/components/home/GenreCard.tsx": _GENRECARD_TSX,
        "src/app/page.tsx": _HOME_TSX,
        "src/app/[genre]/page.tsx": _GENRE_PAGE_TSX,
    }


# ---------- GitHub ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° ----------

_GITHUB_API = "https://api.github.com"


async def provision_github(
    company_id: str,
    access_token: str,
    company_slug: str,
    company_name: str = "",
) -> dict:
    """
    GitHub ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆã—ã€Next.js ãƒœã‚¤ãƒ©ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ push ã™ã‚‹ã€‚

    Returns: {"ok": True, "repo": "owner/repo"} or {"ok": False, "error": "..."}
    """
    repo_name = f"develop_agent-{company_slug}"
    company_name = company_name or company_slug
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
    }

    async with httpx.AsyncClient(timeout=60) as client:
        # 1. èªè¨¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
        user_resp = await client.get(f"{_GITHUB_API}/user", headers=headers)
        if user_resp.status_code != 200:
            return {"ok": False, "error": f"GitHub API auth failed: {user_resp.status_code}"}
        owner = user_resp.json()["login"]
        repo_full = f"{owner}/{repo_name}"

        # 2. ãƒªãƒã‚¸ãƒˆãƒªä½œæˆï¼ˆæ—¢å­˜ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        check_resp = await client.get(f"{_GITHUB_API}/repos/{repo_full}", headers=headers)
        if check_resp.status_code == 404:
            create_resp = await client.post(
                f"{_GITHUB_API}/user/repos",
                headers=headers,
                json={
                    "name": repo_name,
                    "private": True,
                    "auto_init": True,
                    "description": f"AIç¤¾å“¡ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - {company_name}",
                },
            )
            if create_resp.status_code not in (200, 201):
                return {"ok": False, "error": f"Repo create failed: {create_resp.text}"}
            logger.info("Created repo %s", repo_full)
        elif check_resp.status_code == 200:
            logger.info("Repo %s already exists, skipping creation", repo_full)
        else:
            return {"ok": False, "error": f"Repo check failed: {check_resp.status_code}"}

        # 3. ãƒœã‚¤ãƒ©ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ pushï¼ˆContents API ã§1ãƒ•ã‚¡ã‚¤ãƒ«ãšã¤ï¼‰
        files = _boilerplate_files(company_name, repo_name)
        for path, content in files.items():
            encoded = base64.b64encode(content.encode("utf-8")).decode("ascii")
            put_resp = await client.put(
                f"{_GITHUB_API}/repos/{repo_full}/contents/{path}",
                headers=headers,
                json={
                    "message": f"Add {path}",
                    "content": encoded,
                },
            )
            if put_resp.status_code == 422:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ SHA ã‚’å–å¾—ã—ã¦æ›´æ–°
                get_resp = await client.get(
                    f"{_GITHUB_API}/repos/{repo_full}/contents/{path}",
                    headers=headers,
                )
                if get_resp.status_code == 200:
                    sha = get_resp.json().get("sha", "")
                    update_resp = await client.put(
                        f"{_GITHUB_API}/repos/{repo_full}/contents/{path}",
                        headers=headers,
                        json={
                            "message": f"Update {path}",
                            "content": encoded,
                            "sha": sha,
                        },
                    )
                    if update_resp.status_code in (200, 201):
                        logger.info("Updated %s in %s", path, repo_full)
                    else:
                        logger.warning("Failed to update %s: %s", path, update_resp.status_code)
                else:
                    logger.info("File %s exists but could not fetch SHA, skipping", path)
            elif put_resp.status_code not in (200, 201):
                logger.warning("Failed to push %s: %s", path, put_resp.status_code)

    # 4. ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜
    oauth_store.save_token(
        provider="github",
        tenant_id=company_id,
        access_token=access_token,
    )

    # 5. ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®šæ›´æ–°
    company_module.update_company_infra(company_id, {
        "github_repository": repo_full,
        "github_token_secret_name": f"github-token-{company_slug}",
    })

    # 6. ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
    company_module.update_onboarding(company_id, {
        "github_repo": True,
        "github_initial_commit": True,
        "env_github_repository": True,
    })

    return {"ok": True, "repo": repo_full}


# ---------- Supabase ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° ----------

_SUPABASE_MGMT_API = "https://api.supabase.com"


async def provision_supabase(
    company_id: str,
    access_token: str,
    company_slug: str,
) -> dict:
    """
    Supabase Management API ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚

    Returns: {"ok": True, "url": "https://xxx.supabase.co", "anon_key": "..."} or {"ok": False, "error": "..."}
    """
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json",
    }
    db_pass = secrets.token_urlsafe(24)

    async with httpx.AsyncClient(timeout=120) as client:
        # 1. çµ„ç¹”ä¸€è¦§å–å¾—
        org_resp = await client.get(f"{_SUPABASE_MGMT_API}/v1/organizations", headers=headers)
        if org_resp.status_code != 200:
            return {"ok": False, "error": f"Failed to get organizations: {org_resp.status_code} {org_resp.text}"}
        orgs = org_resp.json()
        if not orgs:
            return {"ok": False, "error": "No Supabase organization found. Create one first."}
        org_id = orgs[0]["id"]

        # 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        project_name = f"develop_agent-{company_slug}"
        create_resp = await client.post(
            f"{_SUPABASE_MGMT_API}/v1/projects",
            headers=headers,
            json={
                "name": project_name,
                "organization_id": org_id,
                "region": "ap-northeast-1",
                "db_pass": db_pass,
                "plan": "free",
            },
        )
        if create_resp.status_code not in (200, 201):
            return {"ok": False, "error": f"Project create failed: {create_resp.text}"}

        project = create_resp.json()
        project_ref = project.get("id", "")
        if not project_ref:
            return {"ok": False, "error": "No project ref in response"}

        # 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæº–å‚™å¾…ã¡ï¼ˆæœ€å¤§120ç§’ï¼‰
        import asyncio

        supabase_url = ""
        anon_key = ""
        for _ in range(24):
            await asyncio.sleep(5)
            status_resp = await client.get(
                f"{_SUPABASE_MGMT_API}/v1/projects/{project_ref}",
                headers=headers,
            )
            if status_resp.status_code == 200:
                proj_data = status_resp.json()
                status = proj_data.get("status", "")
                if status == "ACTIVE_HEALTHY":
                    supabase_url = f"https://{project_ref}.supabase.co"
                    break

        if not supabase_url:
            return {"ok": False, "error": "Project did not become ready within 120 seconds"}

        # 4. API ã‚­ãƒ¼å–å¾—ï¼ˆanon + service_roleï¼‰
        service_role_key = ""
        keys_resp = await client.get(
            f"{_SUPABASE_MGMT_API}/v1/projects/{project_ref}/api-keys",
            headers=headers,
        )
        if keys_resp.status_code == 200:
            for key_data in keys_resp.json():
                if key_data.get("name") == "anon":
                    anon_key = key_data.get("api_key", "")
                elif key_data.get("name") == "service_role":
                    service_role_key = key_data.get("api_key", "")

        # 5. ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–ï¼ˆDB æ¥ç¶šå®‰å®šå¾…ã¡ã®ãŸã‚ãƒªãƒˆãƒ©ã‚¤ï¼‰
        tables_ok = False
        for attempt in range(5):
            tables_ok = await _run_sql_on_project(
                client, project_ref, _CLIENT_SUPABASE_SQL,
                mgmt_token=access_token, service_role_key=service_role_key,
            )
            if tables_ok:
                break
            logger.info("Table init attempt %d failed", attempt + 1)
            await asyncio.sleep(5)
        if not tables_ok:
            logger.warning("Table init failed after 5 attempts for project %s", project_ref)

    # 6. ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜ï¼ˆoauth_store + æš—å·åŒ–ã‚«ãƒ©ãƒ ï¼‰
    oauth_store.save_token(
        provider="supabase",
        tenant_id=company_id,
        access_token=access_token,
    )
    company_module.save_infra_token(company_id, "supabase_mgmt_token_enc", access_token)

    # 7. ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®šæ›´æ–°
    company_module.update_company_infra(company_id, {
        "client_supabase_url": supabase_url,
    })

    # 8. ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
    ob_updates = {"supabase_project": True}
    if tables_ok:
        ob_updates["supabase_tables"] = True
    company_module.update_onboarding(company_id, ob_updates)

    return {
        "ok": True,
        "url": supabase_url,
        "anon_key": anon_key,
        "tables_initialized": tables_ok,
    }


async def retry_supabase_tables(
    company_id: str,
    access_token: str,
) -> dict:
    """æ—¢å­˜ã® Supabase ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å¯¾ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–ã‚’ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ã€‚"""
    import asyncio

    # company_infra ã‹ã‚‰ supabase_url ã‚’å–å¾—ã—ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ref ã‚’å‰²ã‚Šå‡ºã™
    infra = company_module.get_company_infra(company_id) or {}
    supabase_url = infra.get("client_supabase_url", "")
    if not supabase_url:
        return {"ok": False, "error": "No Supabase project URL found"}

    # https://xxxxx.supabase.co â†’ xxxxx
    project_ref = supabase_url.replace("https://", "").replace(".supabase.co", "").strip("/")
    if not project_ref:
        return {"ok": False, "error": "Could not parse project ref from URL"}

    # service_role ã‚­ãƒ¼ã‚’ Management API ã‹ã‚‰å–å¾—
    service_role_key = ""
    async with httpx.AsyncClient(timeout=120) as client:
        keys_resp = await client.get(
            f"{_SUPABASE_MGMT_API}/v1/projects/{project_ref}/api-keys",
            headers={
                "Authorization": f"Bearer {access_token}",
                "Content-Type": "application/json",
            },
        )
        if keys_resp.status_code == 200:
            for key_data in keys_resp.json():
                if key_data.get("name") == "service_role":
                    service_role_key = key_data.get("api_key", "")
                    break

        tables_ok = False
        for attempt in range(5):
            tables_ok = await _run_sql_on_project(
                client, project_ref, _CLIENT_SUPABASE_SQL,
                mgmt_token=access_token, service_role_key=service_role_key,
            )
            if tables_ok:
                break
            logger.info("Table retry attempt %d failed", attempt + 1)
            await asyncio.sleep(5)

    if tables_ok:
        company_module.update_onboarding(company_id, {"supabase_tables": True})

    return {
        "ok": tables_ok,
        "tables_initialized": tables_ok,
        "error": "" if tables_ok else f"Table init failed: {last_error}",
    }


# ---------- Vercel ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° ----------

_VERCEL_API = "https://api.vercel.com"


async def provision_vercel(
    company_id: str,
    access_token: str,
    company_slug: str,
    github_repo: str,
    supabase_url: str = "",
    supabase_anon_key: str = "",
) -> dict:
    """
    Vercel API ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã€GitHub ãƒªãƒã¨æ¥ç¶šã€ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã™ã‚‹ã€‚

    Returns: {"ok": True, "url": "https://xxx.vercel.app"} or {"ok": False, "error": "..."}
    """
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json",
    }
    project_name = f"develop_agent-{company_slug}"

    async with httpx.AsyncClient(timeout=60) as client:
        # 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆï¼ˆGitHub ãƒªãƒé€£æºï¼‰
        create_body: dict = {
            "name": project_name,
            "framework": "nextjs",
        }
        if github_repo:
            create_body["gitRepository"] = {
                "type": "github",
                "repo": github_repo,
            }

        create_resp = await client.post(
            f"{_VERCEL_API}/v10/projects",
            headers=headers,
            json=create_body,
        )
        if create_resp.status_code not in (200, 201):
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
            if create_resp.status_code == 409:
                logger.info("Vercel project %s already exists", project_name)
                # æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
                get_resp = await client.get(
                    f"{_VERCEL_API}/v9/projects/{project_name}",
                    headers=headers,
                )
                if get_resp.status_code != 200:
                    return {"ok": False, "error": f"Failed to get existing project: {get_resp.text}"}
                project_data = get_resp.json()
            else:
                return {"ok": False, "error": f"Project create failed: {create_resp.text}"}
        else:
            project_data = create_resp.json()

        project_id = project_data.get("id", "")

        # 2. ç’°å¢ƒå¤‰æ•°è¨­å®š
        env_vars = [
            {"key": "NEXT_PUBLIC_COMPANY_NAME", "value": company_slug, "target": ["production", "preview", "development"], "type": "plain"},
        ]
        if supabase_url:
            env_vars.append(
                {"key": "NEXT_PUBLIC_SUPABASE_URL", "value": supabase_url, "target": ["production", "preview", "development"], "type": "plain"}
            )
        if supabase_anon_key:
            env_vars.append(
                {"key": "NEXT_PUBLIC_SUPABASE_ANON_KEY", "value": supabase_anon_key, "target": ["production", "preview", "development"], "type": "plain"}
            )

        if env_vars and project_id:
            env_resp = await client.post(
                f"{_VERCEL_API}/v10/projects/{project_id}/env",
                headers=headers,
                json=env_vars,
            )
            if env_resp.status_code not in (200, 201):
                logger.warning("Env vars set failed: %s", env_resp.text)

        # 3. åˆå›ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ãƒˆãƒªã‚¬ãƒ¼ï¼ˆGitHub ãƒªãƒé€£æºæ™‚ï¼‰
        if github_repo and project_id:
            deploy_triggered = False
            # æ–¹æ³• 1: Deploy Hook ã‚’ä½œæˆã—ã¦å‘¼ã³å‡ºã™ï¼ˆæœ€ã‚‚ç¢ºå®Ÿï¼‰
            try:
                hook_resp = await client.post(
                    f"{_VERCEL_API}/v1/projects/{project_id}/deploy-hooks",
                    headers=headers,
                    json={"name": "auto-deploy", "ref": "main"},
                )
                if hook_resp.status_code in (200, 201):
                    hook_url = hook_resp.json().get("url", "")
                    if hook_url:
                        trigger_resp = await client.post(hook_url)
                        if trigger_resp.status_code in (200, 201):
                            logger.info("Vercel deployment triggered via deploy hook")
                            deploy_triggered = True
                        else:
                            logger.warning("Deploy hook trigger failed: %s", trigger_resp.status_code)
                else:
                    logger.info("Deploy hook creation failed: %s %s", hook_resp.status_code, hook_resp.text[:200])
            except Exception as e:
                logger.warning("Deploy hook approach failed: %s", e)

            # æ–¹æ³• 2: gitSource APIï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            if not deploy_triggered:
                parts = github_repo.split("/", 1)
                if len(parts) == 2:
                    git_org, git_repo = parts
                    deploy_body = {
                        "name": project_name,
                        "project": project_id,
                        "target": "production",
                        "gitSource": {
                            "type": "github",
                            "org": git_org,
                            "repo": git_repo,
                            "ref": "main",
                        },
                    }
                    deploy_resp = await client.post(
                        f"{_VERCEL_API}/v13/deployments",
                        headers=headers,
                        json=deploy_body,
                    )
                    if deploy_resp.status_code in (200, 201):
                        deploy_data = deploy_resp.json()
                        deploy_url = deploy_data.get("url", "")
                        if deploy_url and not deploy_url.startswith("http"):
                            deploy_url = f"https://{deploy_url}"
                        logger.info("Vercel deployment triggered via API: %s", deploy_url)
                        deploy_triggered = True
                    else:
                        logger.warning("Vercel deployment API failed: %s", deploy_resp.text[:300])

            if not deploy_triggered:
                logger.warning("Could not trigger initial Vercel deployment for %s", project_name)

        # 4. ãƒ‡ãƒ—ãƒ­ã‚¤ URL ã‚’å–å¾—
        # Vercel ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’é™¤å»ã™ã‚‹ãŸã‚ã€
        # æœ€æ–°ãƒ‡ãƒ—ãƒ­ã‚¤ã®å®Ÿ URL ã‹ alias ã‹ã‚‰å–å¾—ã™ã‚‹
        vercel_url = ""
        aliases = project_data.get("alias", [])
        if aliases:
            vercel_url = f"https://{aliases[0]}"
        else:
            # æœ€æ–°ãƒ‡ãƒ—ãƒ­ã‚¤ã‹ã‚‰å®Ÿéš›ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’å–å¾—
            try:
                list_resp = await client.get(
                    f"{_VERCEL_API}/v6/deployments",
                    headers=headers,
                    params={"projectId": project_id, "limit": "1", "target": "production"},
                )
                if list_resp.status_code == 200:
                    deploys = list_resp.json().get("deployments", [])
                    if deploys:
                        deploy_url_raw = deploys[0].get("url", "")
                        if deploy_url_raw:
                            vercel_url = f"https://{deploy_url_raw}"
            except Exception:
                pass
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’é™¤å»
            if not vercel_url and project_data.get("name"):
                domain = project_data["name"].replace("_", "")
                vercel_url = f"https://{domain}.vercel.app"

    # 5. ãƒˆãƒ¼ã‚¯ãƒ³ä¿å­˜ï¼ˆoauth_store + æš—å·åŒ–ã‚«ãƒ©ãƒ ï¼‰
    oauth_store.save_token(
        provider="vercel",
        tenant_id=company_id,
        access_token=access_token,
    )
    company_module.save_infra_token(company_id, "vercel_token_enc", access_token)

    # 6. ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®šæ›´æ–°
    if vercel_url:
        company_module.update_company_infra(company_id, {
            "vercel_project_url": vercel_url,
        })

    # 7. ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
    ob_updates = {"vercel_project": True}
    if supabase_url or supabase_anon_key:
        ob_updates["vercel_env"] = True
    company_module.update_onboarding(company_id, ob_updates)

    return {"ok": True, "url": vercel_url}
